{"name":"FlexGP","tagline":"Tutorial and Blog","body":"# FlexGP: Flexible Symbolic Regression with Genetic Programming\r\nFlexGP is a Genetic Programming framework aimed at data modeling and knowledge discovery. Current release provides functionality both for performing Symbolic Regression on numerical datasets and for testing the retrieved models. In this website we provide a quick tutorial on how to get started with FlexGP.\r\n\r\n# Tutorial\r\n\r\nThis release is only supported for Linux Debian platforms. The functionality of the current release is limited to Symbolic Regression tasks (capability to attack binary classification problems will be added soon).\r\n\r\n## Step 1: Download the flexgp.jar file from [here](https://github.com/flexgp/flexgp.github.io/releases)\r\n\r\n## Step 2: Data format\r\nData must be provided in csv format where each line corresponds to an exemplar and the target values are placed in the last column. Note that any additional line or column containing labels or nominal values needs to be removed.\r\n\r\n## Step 3: Running FlexGP \r\nIn the current release, it is only possible to run FlexGP directly from your terminal (a Matlab wrapper will be included soon).\r\n\r\n### Running FlexGP from the terminal\r\n\r\n#### Model the data\r\nAll you need to provide is the path to your dataset and the optimization time\r\n```\r\n$ java -jar flexgp.jar -train path_to_your_data -minutes 10 \r\n```\r\nAt the end of the run a set of files are generated:\r\n\r\n1. **pareto.txt**: models forming the Pareto Front (accuracy vs model complexity).\r\n\r\n2. **leastComplex.txt**: least complex model of the Pareto Front.\r\n\r\n3. **mostAccurate.txt**: most accurate model of the Pareto Front.\r\n\r\n4. **knee.txt**: model at the knee of the Pareto Front.\r\n\r\n5. **bestModelGeneration.txt**: most accurate model per generation.\r\n\r\n6. **fusedModel.txt**: fused model of the Pareto Front obtained with Adaptive Regression by Mixing (see _Adaptive Regression by Mixing. Yuhong Yang. Journal of the American Statistical Association Vol. 96, No. 454 (Jun., 2001), pp. 574-588_).\r\n\r\n\r\n#### Test the models\r\nFlexGP provides functionality to obtain the Mean Squared Error (MSE) of the retrieved models once the training is finished. In the examples below, the additional _-integer_ flag indicates whether the targets are integer or floating point values. To test the models saved in files 1) to 5), do:\r\n```\r\n$ java -jar flexgp.jar -test path_to_your_data -integer true -scaled model_file \r\n```\r\nTo obtain the MSE of the fused model of the Pareto Front:\r\n```\r\n$ java -jar flexgp.jar -test path_to_your_data -integer false -fused model_file \r\n```\r\n\r\n\r\n### Running FlexGP from Matlab\r\nTo be done\r\n\r\n## Step 3: Speeding up your runs with C++ optimized execution\r\nThis option requires the installation of the gcc and g++ compilers and the configuration of the Linux kernel parameter governing the maximum size of shared memory segments:\r\n```\r\n$ sudo apt-get install gcc\r\n$ sudo apt-get install g++\r\n```\r\nModify the Linux kernel parameter governing the maximum shared memory segment size to be at least as large as the data being analyzed, in the next example we set it to 2GB\r\n```\r\n$ sudo echo 2147483648 > /proc/sys/kernel/shmmax\r\n```\r\nTo benefit from the optimized C++ execution, append the -cpp flag followed by the number of CPU threads that will be employed to speedup FlexGP (4 in the example below). Additionally, it is necessary to create an auxiliary default folder in which temporary C++ files will be generated:\r\n```\r\n$ mkdir tempFiles\r\n$ java -jar flexgp.jar -train path_to_your_data -minutes 10 -cpp 4\r\n```\r\n# Results\r\nTo check reports visit our blog:\r\n[FlexGP Blog](blog.html)\r\n\r\n# Support or Contact\r\nThis page has been created by the Any-scale Learning For All (ALFA) group at MIT. Please contact us at: flexgp@csail.mit.edu \r\n\r\nauthor: @ignacioarnaldo\r\n","google":"flexgp","note":"Don't delete this file! It's used internally to help with page regeneration."}